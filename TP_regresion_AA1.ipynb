{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trabajo Práctico N° 1\n",
        "\n",
        "**Año:** 2024  \n",
        "\n",
        "**Materia:** Aprendizaje Automatico 1\n",
        "\n",
        "**Integrantes:** Avecilla Tomás, Calcia Franco\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emdFaxAN6_xs"
      },
      "source": [
        "### Diccionario  de Datos\n",
        "\n",
        "| Columna       | Descripción                                                                                          |\n",
        "|---------------|---------------------------------------------------------------------------------------------------------------|\n",
        "| **CRIM** | Tasa de criminalidad per cápita por ciudad.                       |\n",
        "| **ZN**   | Proporción de terrenos residenciales zonificados para lotes de más de 25,000 pies cuadrados.                         |\n",
        "| **INDUS**   | Proporción de acres de negocios no minoristas por ciudad.                         |\n",
        "| **CHAS** | Variable dummy del río Charles (1 si el tramo limita con el río; 0 de lo contrario).                                                             |\n",
        "| **NOX**   | Concentración de óxidos de nitrógeno (partes por 10 millones) [parts/10M].                                                          |\n",
        "| **RM**        | Número promedio de habitaciones por vivienda.|\n",
        "| **AGE**    | Proporción de unidades ocupadas por sus propietarios construidas antes de 1940.                                                        |\n",
        "| **DIS**   | Distancias ponderadas a cinco centros de empleo de Boston.       |\n",
        "| **RAD** | índice de accesibilidad a las autopistas radiales.                                                             |\n",
        "| **TAX**   | Tasa de impuesto sobre la propiedad a valor completo por $10,000 [$/10k].                                                          |\n",
        "| **PTRATIO**        | Proporción alumno-maestro por ciudad.|\n",
        "| **B**    | El resultado de la ecuación B=1000(Bk - 0.63)^2 donde Bk es la proporción de negros por ciudad.                                                        |\n",
        "| **LSTAT**   | % de población de menor estatus socioeconómico.       |\n",
        "| **MEDV** *(Variable de salida)*  | Valor mediano de las viviendas ocupadas por sus propietarios en miles de dólares [k$].   | \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVVs2jH58Qyt"
      },
      "source": [
        "# Preparacion del entorno de Trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "Ik47qb-VCF8L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, mean_absolute_error\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from sklearn.preprocessing import RobustScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "VLVElyf2CPwO"
      },
      "outputs": [],
      "source": [
        "df_precios_casas = pd.read_csv(\"house-prices-tp.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThPT2Wc76_xx"
      },
      "source": [
        "# Train-Test\n",
        "Decidimos hacer la division del dataset antes de comenzar el analisis y hacer cualquier tratado de datos ya que necesitamos que el dataset de testeo sea tomado como datos desconocidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "Dcn_d2I66_xx"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_precios_casas.drop(columns=['MEDV']), df_precios_casas['MEDV'], test_size=0.2, random_state=42)\n",
        "\n",
        "df_entrenamiento = pd.concat([X_train,y_train],axis=1)\n",
        "df_test = pd.concat([X_test,y_test],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SKvtI-c6_xu"
      },
      "source": [
        "# Análisis Exploratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g8o5BJABC6N"
      },
      "source": [
        "## Limpieza de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfJumZYU6_xv"
      },
      "source": [
        "### Verificamos valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "hJbcu1P8CepE",
        "outputId": "210603ac-50ec-4bde-c05b-27805c6efebc"
      },
      "outputs": [],
      "source": [
        "conteo_nan = df_entrenamiento.isnull().sum()\n",
        "conteo_nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD4F-YKtBS0_"
      },
      "source": [
        "Como primera medida eliminaremos las fila que tengan la variable de salida nula o mas de 11 columnas nulas ya que las consideramos irrelevantes para el analisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n08LNR7CSWf7",
        "outputId": "e1f63442-36f9-4234-be25-0a69c9cd5b15"
      },
      "outputs": [],
      "source": [
        "filas_nan = []\n",
        "\n",
        "for index, row in df_entrenamiento.iterrows():\n",
        "    # Verificamos si la fila tiene más de 11 NaN o si el valor de MEDV es NaN\n",
        "    if row.isnull().sum() > 11 or pd.isnull(row['MEDV']):\n",
        "        filas_nan.append(index)\n",
        "\n",
        "df_entrenamiento.drop(index=filas_nan, inplace=True)\n",
        "\n",
        "print(f\"Filas eliminadas: {len(filas_nan)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "XbwelUT-6_xw",
        "outputId": "e21e8a57-0362-4220-a33d-841b5507d152"
      },
      "outputs": [],
      "source": [
        "conteo_nan = df_entrenamiento.isnull().sum()\n",
        "conteo_nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amymG2Eb6_xw"
      },
      "source": [
        "Imputaremos la columna binaria con la moda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "ww_xBD7L6_xw"
      },
      "outputs": [],
      "source": [
        "df_entrenamiento['CHAS'] = df_entrenamiento['CHAS'].fillna(df_entrenamiento['CHAS'].mode()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZOTyJj9Dcgr"
      },
      "source": [
        "Y el resto de columnas seran imputadas con KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "GKff5cv5FjJ1"
      },
      "outputs": [],
      "source": [
        "imputer = KNNImputer(n_neighbors=5)\n",
        "df_entrenamiento = pd.DataFrame(imputer.fit_transform(df_entrenamiento), columns=df_entrenamiento.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conteo_nan = df_entrenamiento.isnull().sum()\n",
        "conteo_nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E_PD9c56_xy"
      },
      "source": [
        "### Exploracion de outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7uhm6C46_xy",
        "outputId": "2f723d8e-70e0-4d21-e979-562b6210a3e2"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "num_columns = len(df_entrenamiento.columns)\n",
        "\n",
        "max_plots_per_figure = 12\n",
        "num_figures = (num_columns + max_plots_per_figure - 1) // max_plots_per_figure\n",
        "\n",
        "for fig_index in range(num_figures):\n",
        "    start_index = fig_index * max_plots_per_figure\n",
        "    end_index = min(start_index + max_plots_per_figure, num_columns)\n",
        "\n",
        "    plt.figure(figsize=(15, 5 * ((end_index - start_index + 2) // 2)))\n",
        "\n",
        "    for i, column in enumerate(df_entrenamiento.columns[start_index:end_index]):\n",
        "        plt.subplot((end_index - start_index + 2) // 3, 3, i + 1)\n",
        "        if column == 'CHAS':\n",
        "            sns.countplot(data=df_entrenamiento, x='CHAS')\n",
        "            plt.title('Distribución de CHAS')\n",
        "        else:\n",
        "            sns.boxplot(data=df_entrenamiento[column], color=\"skyblue\")\n",
        "            plt.title(column)\n",
        "        plt.xlabel('')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96eGHe2ECaDW"
      },
      "source": [
        "Podemos notar varias variables con presencia de outliers por lo cual deberiamos hacer un analisis mas profundo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLXpoCtiC_3a",
        "outputId": "38c90ffb-ab42-4407-e598-7394eef7ddc3"
      },
      "outputs": [],
      "source": [
        "resultados_atipicos = {}\n",
        "\n",
        "for columna in df_entrenamiento.columns:\n",
        "    if df_entrenamiento[columna].dtype in ['int64', 'float64']:\n",
        "        Q1 = df_entrenamiento[columna].quantile(0.25)\n",
        "        Q3 = df_entrenamiento[columna].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        limite_inferior = Q1 - 1.5 * IQR\n",
        "        limite_superior = Q3 + 1.5 * IQR\n",
        "\n",
        "        es_atipico = (df_entrenamiento[columna] < limite_inferior) | (df_entrenamiento[columna] > limite_superior)\n",
        "\n",
        "        cantidad_atipicos = es_atipico.sum()\n",
        "        porcentaje_atipicos = (cantidad_atipicos / len(df_entrenamiento)) * 100\n",
        "\n",
        "        resultados_atipicos[columna] = porcentaje_atipicos\n",
        "\n",
        "for columna, porcentaje in resultados_atipicos.items():\n",
        "    print(f\"Columna: {columna} - Porcentaje de valores atípicos: {porcentaje:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPEfoYlPARvl"
      },
      "source": [
        "## Analisis Descriptivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmTVC1F2CYUP",
        "outputId": "7ecd76c3-410b-4827-922f-2020fd4b1000"
      },
      "outputs": [],
      "source": [
        "df_entrenamiento.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrzmnuYo6_xv",
        "outputId": "5b008ddb-94a9-45cf-e763-c0ce7bc439d2"
      },
      "outputs": [],
      "source": [
        "df_entrenamiento.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFV4K2aV6_xx",
        "outputId": "8bde2f2b-25de-453d-b408-ef33b5f985c5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_entrenamiento['MEDV'], bins=30, kde=True)\n",
        "plt.title('variable Target')\n",
        "plt.xlabel('Precio')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um5Ol_236_xx",
        "outputId": "9925b20c-8856-4d1c-aeb8-b68c0c87036f"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "sns.pairplot(\n",
        "    df_entrenamiento,\n",
        "    diag_kind='kde',\n",
        "    plot_kws={'alpha': 0.6, 'color': 'orange', 's': 15},\n",
        "    diag_kws={'color': 'red', 'fill': True},  # Cambiado 'shade' por 'fill'\n",
        "    height=2.5,\n",
        "    aspect=1,\n",
        "    corner=True,\n",
        ")\n",
        "\n",
        "plt.suptitle('Pairplot de Variables del DataFrame de Entrenamiento', fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkaWvxkM6_xx"
      },
      "source": [
        "#### Matriz de correlación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1f0sfL66_xx",
        "outputId": "bd7a0dff-4cb6-43dc-d5f4-df1966045e4d"
      },
      "outputs": [],
      "source": [
        "corr_matrix = df_entrenamiento.corr()\n",
        "\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "\n",
        "colors = [(1, 1, 1), (1, 0, 0)]\n",
        "n_bins = 100\n",
        "cmap_name = 'red_white'\n",
        "cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='vlag', center=0, vmin=-1, vmax=1, linewidths=0.5)\n",
        "plt.title('Matriz de correlación')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpc15AMDD7d7"
      },
      "source": [
        "Notamos una fuerte relacion entre las variables TAX-RAD (0.88) y NOX-INDUS (0.74)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdsAROI-EpSO"
      },
      "source": [
        "# Valores nulos en dataset de testeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "o1zC6MbAE1jv",
        "outputId": "c2fb35d1-4cb2-495a-e1d3-94afa4ac29f6"
      },
      "outputs": [],
      "source": [
        "df_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMfeXjptFDCA"
      },
      "source": [
        "Usamos el mismo criterio que en el dataset de entrenamiento para eliminar filas completas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxbG6zjfFCcw",
        "outputId": "a6377bb8-e26c-40ff-b168-d9e4556bb119"
      },
      "outputs": [],
      "source": [
        "filas_nan = []\n",
        "\n",
        "for index, row in df_test.iterrows():\n",
        "    # Verificamos si la fila tiene más de 11 NaN o si el valor de MEDV es NaN\n",
        "    if row.isnull().sum() > 11 or pd.isnull(row['MEDV']):\n",
        "        filas_nan.append(index)\n",
        "\n",
        "df_test.drop(index=filas_nan, inplace=True)\n",
        "\n",
        "print(f\"Filas eliminadas: {len(filas_nan)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTpS3cJeFXjR"
      },
      "source": [
        "Aqui repetimos el criterio de rellenar con la moda que en el caso del entrenamiento fue de `0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "9yD5FH3TFRz5"
      },
      "outputs": [],
      "source": [
        "df_test['CHAS'] = df_test['CHAS'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "DOXkJmUYF14D",
        "outputId": "6daf488a-ef02-44eb-bd8b-1cb1730efd19"
      },
      "outputs": [],
      "source": [
        "df_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyhwFsycFrhr"
      },
      "source": [
        "Y por ultimo usamos el mismo `imputer` para rellenar los restantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "1GX2JLISFi2C"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(imputer.fit_transform(df_test), columns=df_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "KX6mCAn1F2az",
        "outputId": "d6ed770d-0aca-4f57-8477-d2d44533309b"
      },
      "outputs": [],
      "source": [
        "df_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Escalar los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separar en X_train, y_train, X_test, y_test\n",
        "X_train = df_entrenamiento.drop(columns=['MEDV'])\n",
        "y_train = df_entrenamiento['MEDV']\n",
        "X_test = df_test.drop(columns=['MEDV'])\n",
        "y_test = df_test['MEDV']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escalar los datos\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regresión lineal simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regresion_lineal = LinearRegression()\n",
        "regresion_lineal.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gradientes Descendentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradiente Descendente Estocastico (SGD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(X_train, y_train, X_test, y_test, lr, epochs):\n",
        "    n = X_train.shape[0]\n",
        "    m = X_train.shape[1]\n",
        "\n",
        "    # Agregar el término de sesgo (bias) a las matrices de entrada\n",
        "    X_train = np.hstack((np.ones((n, 1)), X_train))\n",
        "    X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "    # Inicializar los pesos de forma aleatoria\n",
        "    W = np.random.randn(m + 1, 1)\n",
        "\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "\n",
        "    # Convertir y_train y y_test a numpy.ndarray\n",
        "    y_train = y_train.to_numpy().reshape(-1, 1)\n",
        "    y_test = y_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        # Permutación aleatoria de los datos\n",
        "        permutation = np.random.permutation(n)\n",
        "        X_train = X_train[permutation]\n",
        "        y_train = y_train[permutation].reshape(-1, 1)  # Asegurarse de que y_train sea un vector columna\n",
        "\n",
        "        for j in range(n):\n",
        "            # Obtener una muestra aleatoria de un solo dato para hacer SGD\n",
        "            x_sample = X_train[j].reshape(1, -1)\n",
        "            y_sample = y_train[j]\n",
        "\n",
        "            prediction = np.matmul(x_sample, W)\n",
        "            error = y_sample - prediction\n",
        "            train_mse = error ** 2\n",
        "            train_errors.append(train_mse[0])\n",
        "\n",
        "            prediction_test = np.matmul(X_test, W)\n",
        "            error_test = y_test - prediction_test  # Asegurarse de que y_test sea un vector columna\n",
        "            test_mse = np.mean(error_test ** 2)\n",
        "            test_errors.append(test_mse)\n",
        "\n",
        "            gradient = -2 * error * x_sample.T\n",
        "            W = W - (lr * gradient)\n",
        "\n",
        "            \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_errors, label='Error de entrenamiento')\n",
        "    plt.plot(test_errors, label='Error de prueba')\n",
        "    plt.xlabel('Iteración')\n",
        "    plt.ylabel('Error cuadrático medio')\n",
        "    plt.legend()\n",
        "    plt.title('Error de entrenamiento y prueba vs iteraciones (SGD)')\n",
        "    plt.show()\n",
        "\n",
        "    return W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradiente Descendente (Batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradiente descendente (GD o Batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observaciones del Gráfico de MSE en Stochastic Gradient Descent (SGD)\n",
        "\n",
        "1. **Curva de error de entrenamiento y prueba**:\n",
        "   - Inicialmente, el *error cuadrático medio (MSE)* es alto tanto para los datos de entrenamiento como para los de prueba.\n",
        "   - Sin embargo, el error desciende rápidamente en las primeras iteraciones (aproximadamente dentro de las primeras 2000 iteraciones).\n",
        "   - Después de esta rápida caída inicial, tanto el error de entrenamiento como el error de prueba se estabilizan cerca de 0, manteniéndose prácticamente planos durante el resto de las iteraciones (hasta las 30,000).\n",
        "\n",
        "2. **Posible explicación del comportamiento**:\n",
        "   - Este comportamiento indica que el modelo ha *convergido correctamente* y está ajustando tanto los datos de entrenamiento como los de prueba de manera adecuada.\n",
        "   - La rápida disminución del error en las primeras iteraciones es característica del *SGD*, donde, con una tasa de aprendizaje adecuada, el modelo ajusta sus pesos rápidamente hacia un mínimo local o global.\n",
        "   - La estabilización del error en valores muy bajos para ambas curvas es un buen indicio de que el modelo está bien generalizado y no está sobreajustando, ya que los errores de prueba y entrenamiento son similares y bajos.\n",
        "\n",
        "3. **Interpretación general**:\n",
        "   - Este gráfico sugiere que el modelo está funcionando bien y que el proceso de aprendizaje está controlado, sin problemas de *divergencia*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 408,
      "metadata": {
        "id": "23J8fGxx6_x2"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(X_train, y_train, X_val, y_val, lr, epochs):\n",
        "    \"\"\"\n",
        "    shapes:\n",
        "        X_train = nxm\n",
        "        y_train = nx1\n",
        "        X_val = pxm\n",
        "        y_val = px1\n",
        "        W = mx1\n",
        "    \"\"\"\n",
        "    n = X_train.shape[0]  # Número de ejemplos de entrenamiento\n",
        "    m = X_train.shape[1]  # Número de características\n",
        "\n",
        "    o = X_val.shape[0]  # Número de ejemplos de validación\n",
        "\n",
        "    # Poner columna de unos a las matrices X para el término de sesgo (bias)\n",
        "    X_train = np.hstack((np.ones((n, 1)), X_train))\n",
        "    X_val = np.hstack((np.ones((o, 1)), X_val))\n",
        "\n",
        "    # Convertir y_train y y_val a arrays de NumPy y asegurarse de que sean vectores columna\n",
        "    y_train = y_train.to_numpy().reshape(-1, 1)\n",
        "    y_val = y_val.to_numpy().reshape(-1, 1)\n",
        "\n",
        "    # Inicializar pesos aleatorios\n",
        "    W = np.random.randn(m + 1).reshape(m + 1, 1)\n",
        "\n",
        "    train_errors = []  # Para almacenar el error de entrenamiento en cada época\n",
        "    val_errors = []    # Para almacenar el error de validación en cada época\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        # Calcular predicción y error de entrenamiento\n",
        "        prediction_train = np.matmul(X_train, W)\n",
        "        error_train = y_train - prediction_train\n",
        "        train_mse = np.mean(error_train ** 2)\n",
        "        train_errors.append(train_mse)\n",
        "\n",
        "        # Calcular predicción y error de validación\n",
        "        prediction_val = np.matmul(X_val, W)\n",
        "        error_val = y_val - prediction_val\n",
        "        val_mse = np.mean(error_val ** 2)\n",
        "        val_errors.append(val_mse)\n",
        "\n",
        "        # Calcular el gradiente y actualizar pesos\n",
        "        grad_sum = np.sum(error_train * X_train, axis=0)\n",
        "        grad_mul = -2 / n * grad_sum  # 1xm\n",
        "        gradient = np.transpose(grad_mul).reshape(-1, 1)  # mx1\n",
        "\n",
        "        W = W - (lr * gradient)\n",
        "\n",
        "    # Graficar errores de entrenamiento y validación\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_errors, label='Error de entrenamiento')\n",
        "    plt.plot(val_errors, label='Error de validación')\n",
        "    plt.xlabel('Época')\n",
        "    plt.ylabel('Error cuadrático medio')\n",
        "    plt.legend()\n",
        "    plt.title('Error de entrenamiento y validación vs iteraciones (GD)')\n",
        "    plt.show()\n",
        "\n",
        "    return W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observaciones del Gradiente Descendente (Batch GD)\n",
        "\n",
        "En este gráfico, observamos cómo el error de entrenamiento y el error de validación disminuyen a lo largo de las épocas. \n",
        "\n",
        "- El error de ambos (entrenamiento y validación) decrece continuamente conforme el modelo ajusta sus parámetros, lo cual es una señal de que el gradiente descendente está funcionando correctamente.\n",
        "- A medida que las épocas avanzan, las curvas comienzan a estabilizarse, lo que indica que el modelo está convergiendo a un mínimo local del error.\n",
        "\n",
        "**Conclusión:**\n",
        "\n",
        "Este comportamiento es típico de un modelo bien entrenado, donde el error de entrenamiento disminuye de manera constante, y el error de validación también mejora, lo que sugiere que el modelo no está sobreajustando los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradiente Descedente por lotes (Mini-Batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradiente Descendente Mini-Batch GD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 410,
      "metadata": {
        "id": "sC_Tncou6_x3"
      },
      "outputs": [],
      "source": [
        "def mini_batch_gradient_descent(X_train, y_train, X_test, y_test, lr, epochs, batch_size):\n",
        "    n = X_train.shape[0]\n",
        "    m = X_train.shape[1]\n",
        "\n",
        "    X_train = np.hstack((np.ones((n, 1)), X_train))\n",
        "    X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "    y_train = y_train.to_numpy().reshape(-1, 1)\n",
        "    y_test = y_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "    W = np.random.randn(m + 1).reshape(-1, 1)\n",
        "\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "\n",
        "    for i in range(epochs):\n",
        "        # Permutación aleatoria de los datos\n",
        "        permutation = np.random.permutation(n)\n",
        "        X_train = X_train[permutation]\n",
        "        y_train = y_train[permutation]\n",
        "\n",
        "        for j in range(0, n, batch_size):\n",
        "            # Obtener un lote (mini-batch) de datos\n",
        "            x_batch = X_train[j:j+batch_size, :]\n",
        "            y_batch = y_train[j:j+batch_size].reshape(-1, 1)\n",
        "\n",
        "            prediction = np.matmul(x_batch, W)\n",
        "            error = y_batch - prediction\n",
        "            train_mse = np.mean(error ** 2)\n",
        "            train_errors.append(train_mse)\n",
        "\n",
        "            gradient = -2 * np.matmul(x_batch.T, error) / batch_size\n",
        "\n",
        "            W = W - (lr * gradient)\n",
        "\n",
        "            prediction_test = np.matmul(X_test, W)\n",
        "            error_test = y_test - prediction_test\n",
        "            test_mse = np.mean(error_test ** 2)\n",
        "            test_errors.append(test_mse)\n",
        "\n",
        "            \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_errors, label='Error de entrenamiento')\n",
        "    plt.plot(test_errors, label='Error de prueba')\n",
        "    plt.xlabel('Iteración')\n",
        "    plt.ylabel('Error cuadrático medio')\n",
        "    plt.legend()\n",
        "    plt.title('Error de entrenamiento y prueba vs iteraciones (Mini-Batch GD)')\n",
        "    plt.show()\n",
        "\n",
        "    return W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelos de Regularización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "regresiones_lineales = {\n",
        "    \"Lasso\": LassoCV(alphas=np.logspace(-4, 4, 20), cv=5, random_state=42),\n",
        "    \"Ridge\": RidgeCV(alphas=np.logspace(-4, 4, 20), cv=5),\n",
        "    \"ElasticNet\": ElasticNetCV(alphas=np.logspace(-4, 4, 20), l1_ratio=np.linspace(0.1, 1, 10), cv=5, random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluación de Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluar_modelo(modelo, nombre_modelo, X_train, y_train, X_test, y_test):\n",
        "    y_train_pred = modelo.predict(X_train)\n",
        "    y_test_pred = modelo.predict(X_test)\n",
        "\n",
        "    resultados = {\n",
        "        \"Modelo\": nombre_modelo,\n",
        "        \"Train RMSE\": mean_squared_error(y_train, y_train_pred),\n",
        "        \"Test RMSE\": mean_squared_error(y_test, y_test_pred),\n",
        "        \"Train R2\": r2_score(y_train, y_train_pred),\n",
        "        \"Test R2\": r2_score(y_test, y_test_pred),\n",
        "        \"Train MSE\": mean_squared_error(y_train, y_train_pred),\n",
        "        \"Test MSE\": mean_squared_error(y_test, y_test_pred),\n",
        "        \"Train MAE\": mean_squared_error(y_train, y_train_pred),\n",
        "        \"Test MAE\": mean_squared_error(y_test, y_test_pred),\n",
        "        \"Train MAPE\": mean_absolute_percentage_error(y_train, y_train_pred),\n",
        "        \"Test MAPE\": mean_absolute_percentage_error(y_test, y_test_pred)\n",
        "    }\n",
        "\n",
        "    return resultados\n",
        "\n",
        "def calcular_metricas(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
        "    return mse, mae, mape\n",
        "\n",
        "def evaluar_gradiente(W, X_train, X_test, y_train, y_test, nombre_modelo):\n",
        "    X_train_bias = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "    X_test_bias = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "    y_train_pred = np.dot(X_train_bias, W).flatten()\n",
        "    y_test_pred = np.dot(X_test_bias, W).flatten()\n",
        "\n",
        "    train_mse, train_mae, train_mape = calcular_metricas(y_train, y_train_pred)\n",
        "    test_mse, test_mae, test_mape = calcular_metricas(y_test, y_test_pred)\n",
        "\n",
        "    resultados = {\n",
        "        \"Modelo\": nombre_modelo,\n",
        "        \"Train RMSE\": np.sqrt(train_mse),\n",
        "        \"Test RMSE\": np.sqrt(test_mse),\n",
        "        \"Train R2\": r2_score(y_train, y_train_pred),\n",
        "        \"Test R2\": r2_score(y_test, y_test_pred),\n",
        "        \"Train MSE\": train_mse,\n",
        "        \"Test MSE\": test_mse,\n",
        "        \"Train MAE\": train_mae,\n",
        "        \"Test MAE\": test_mae,\n",
        "        \"Train MAPE\": train_mape,\n",
        "        \"Test MAPE\": test_mape\n",
        "    }\n",
        "\n",
        "    return resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados_finales = []\n",
        "\n",
        "# Regresión lineal simple\n",
        "resultados_finales.append(evaluar_modelo(regresion_lineal, \"Regresión Lineal\", X_train_scaled, y_train, X_test_scaled, y_test))\n",
        "\n",
        "# Gradiente descendente (modelos obtenidos por SGD, Batch y Mini-batch)\n",
        "W_sgd = stochastic_gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.001, epochs=1000)\n",
        "W_batch = gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.001, epochs=1000)\n",
        "W_mini_batch = mini_batch_gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.01, epochs=100, batch_size=25)\n",
        "\n",
        "# Evaluar los modelos obtenidos por gradientes\n",
        "resultados_finales.append(evaluar_gradiente(W_sgd, X_train_scaled, X_test_scaled, y_train, y_test, \"SGD\"))\n",
        "resultados_finales.append(evaluar_gradiente(W_batch, X_train_scaled, X_test_scaled, y_train, y_test, \"Batch Gradient Descent\"))\n",
        "resultados_finales.append(evaluar_gradiente(W_mini_batch, X_train_scaled, X_test_scaled, y_train, y_test, \"Mini-Batch Gradient Descent\"))\n",
        "# Evaluación de regularización (Lasso, Ridge, ElasticNet)\n",
        "for name, regressor in regresiones_lineales.items():\n",
        "    regressor.fit(X_train_scaled, y_train)\n",
        "    resultados_finales.append(evaluar_modelo(regressor, name, X_train_scaled, y_train, X_test_scaled, y_test))\n",
        "\n",
        "# Mostrar los resultados finales\n",
        "resultados_df = pd.DataFrame(resultados_finales)\n",
        "resultados_df.head(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpretación de los Gráficos\n",
        "\n",
        "## 1. Stochastic Gradient Descent (SGD)\n",
        "\n",
        "**Análisis:**\n",
        "- El error de entrenamiento es extremadamente errático, con oscilaciones muy grandes. Esto es esperado en SGD, ya que utiliza una muestra aleatoria de los datos en cada iteración, lo que genera una alta variabilidad.\n",
        "- El error de prueba, por otro lado, es mucho más estable y más bajo, lo que sugiere que, a pesar de las oscilaciones del entrenamiento, el modelo generaliza bien en el conjunto de prueba.\n",
        "\n",
        "**Conclusión:** Aunque SGD tiene un comportamiento muy volátil en el entrenamiento, parece estar generalizando bien en el conjunto de prueba. Sin embargo, esta volatilidad podría reducirse ajustando la tasa de aprendizaje o implementando técnicas como el decaimiento de la tasa de aprendizaje.\n",
        "\n",
        "## 2. Gradient Descent (GD)\n",
        "\n",
        "**Análisis:**\n",
        "- El error disminuye rápidamente al principio y luego se estabiliza alrededor de una misma línea para el entrenamiento y la validación, lo que indica que el modelo está convergiendo de manera efectiva.\n",
        "- No hay oscilaciones pronunciadas, lo cual es característico del Gradient Descent estándar, ya que utiliza todo el conjunto de datos para cada iteración.\n",
        "\n",
        "**Conclusión:** GD muestra un comportamiento de convergencia suave y estable, con un bajo riesgo de sobreajuste, ya que los errores de entrenamiento y validación son casi idénticos.\n",
        "\n",
        "## 3. Mini-Batch Gradient Descent (MBGD)\n",
        "\n",
        "**Análisis:**\n",
        "- El error de entrenamiento disminuye rápidamente en las primeras iteraciones, lo cual es un comportamiento esperado.\n",
        "- Se observa que oscila considerablemente a lo largo de las iteraciones, lo que es típico en el Mini-Batch GD debido a la naturaleza de los lotes pequeños de datos.\n",
        "- El error de prueba sigue un patrón similar pero tiene menos variabilidad, lo que sugiere que el modelo es estable en el conjunto de prueba a pesar de las oscilaciones en el entrenamiento.\n",
        "\n",
        "**Conclusión:** Mini-Batch GD logra una rápida convergencia inicial, pero las oscilaciones indican que podría necesitar una tasa de aprendizaje más pequeña o un tamaño de lote más grande para reducir la variabilidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpretación del Cuadro\n",
        "\n",
        "## Regresión Lineal:\n",
        "- **Train RMSE (32.07) vs. Test RMSE (40.45):** El error en el conjunto de prueba es significativamente mayor que en el de entrenamiento, lo que puede indicar que el modelo está sobreajustado.\n",
        "- **Train R² (0.64) vs. Test R² (0.58):** El modelo explica el 64% de la variación en el conjunto de entrenamiento y el 58% en el conjunto de prueba, lo que sugiere una ligera disminución en la capacidad predictiva cuando se prueban datos nuevos.\n",
        "- **Train MSE (32.07) vs. Test MSE (40.45):** El error cuadrático medio sigue la misma tendencia que el RMSE, con un aumento en el conjunto de prueba.\n",
        "- **Train MAE (32.07) vs. Test MAE (40.45):** El error absoluto medio es bastante alto, lo que refleja un rendimiento poco preciso en la predicción.\n",
        "- **Train MAPE (0.19) vs. Test MAPE (0.23):** El error porcentual absoluto medio aumenta del 19% en el entrenamiento al 23% en el conjunto de prueba, lo que refleja una menor precisión predictiva.\n",
        "\n",
        "**Conclusión:** El modelo de regresión lineal presenta un desempeño moderado, con indicios de sobreajuste y un error considerable en las predicciones.\n",
        "\n",
        "## SGD (Stochastic Gradient Descent):\n",
        "- **Train RMSE (5.68) vs. Test RMSE (6.22):** El error aumenta ligeramente en el conjunto de prueba, lo cual es normal y sugiere una buena generalización del modelo.\n",
        "- **Train R² (0.65) vs. Test R² (0.60):** El modelo mantiene una alta capacidad predictiva, explicando el 65% de la variación en el conjunto de entrenamiento y el 60% en el de prueba.\n",
        "- **Train MSE (32.21) vs. Test MSE (38.71):** El MSE sigue la misma tendencia que el RMSE, con un aumento moderado en el conjunto de prueba.\n",
        "- **Train MAE (3.82) vs. Test MAE (4.16):** El error absoluto medio es bajo en ambos conjuntos, lo que indica una buena capacidad para realizar predicciones precisas.\n",
        "- **Train MAPE (0.19) vs. Test MAPE (0.23):** El error porcentual absoluto medio aumenta ligeramente en el conjunto de prueba, reflejando una pérdida leve de precisión.\n",
        "\n",
        "**Conclusión:** El modelo SGD tiene un rendimiento sólido, generalizando bien en el conjunto de prueba y con errores menores que los modelos lineales regulares.\n",
        "\n",
        "## Batch Gradient Descent:\n",
        "- **Train RMSE (8.13) vs. Test RMSE (7.70):** El error es menor en el conjunto de prueba que en el de entrenamiento, lo cual podría indicar un posible subajuste del modelo.\n",
        "- **Train R² (0.22) vs. Test R² (0.38):** El modelo mejora su capacidad predictiva en el conjunto de prueba, lo que sugiere que no está aprendiendo adecuadamente de los datos de entrenamiento.\n",
        "- **Train MSE (69.10) vs. Test MSE (59.30):** El error cuadrático medio es mayor en el conjunto de entrenamiento que en el de prueba, lo cual sigue la tendencia del RMSE.\n",
        "- **Train MAE (6.38) vs. Test MAE (6.29):** El error absoluto medio es similar en ambos conjuntos.\n",
        "- **Train MAPE (0.29) vs. Test MAPE (0.32):** El error porcentual absoluto medio es moderadamente mayor en el conjunto de prueba.\n",
        "\n",
        "**Conclusión:** El modelo Batch Gradient Descent parece estar subajustado, lo que resulta en un mejor rendimiento en el conjunto de prueba que en el de entrenamiento.\n",
        "\n",
        "## Mini-Batch Gradient Descent:\n",
        "- **Train RMSE (5.73) vs. Test RMSE (6.51):** El error aumenta en el conjunto de prueba, pero sigue siendo bastante bajo, lo que sugiere una buena generalización.\n",
        "- **Train R² (0.63) vs. Test R² (0.57):** El modelo mantiene una capacidad predictiva sólida, explicando el 63% de la variación en el conjunto de entrenamiento y el 57% en el de prueba.\n",
        "- **Train MSE (32.84) vs. Test MSE (42.38):** El MSE sigue la misma tendencia que el RMSE, con un aumento en el conjunto de prueba.\n",
        "- **Train MAE (3.93) vs. Test MAE (4.32):** El error absoluto medio es bajo en ambos conjuntos.\n",
        "- **Train MAPE (0.20) vs. Test MAPE (0.25):** El error porcentual absoluto medio aumenta ligeramente en el conjunto de prueba.\n",
        "\n",
        "**Conclusión:** El modelo Mini-Batch Gradient Descent ofrece un buen equilibrio entre ajuste y generalización, con errores relativamente bajos y consistentes.\n",
        "\n",
        "## Lasso:\n",
        "- **Train RMSE (32.09) vs. Test RMSE (40.42):** Los errores son muy similares a los de la regresión lineal, sin una mejora significativa.\n",
        "- **Train R² (0.64) vs. Test R² (0.58):** La capacidad predictiva es prácticamente idéntica a la de la regresión lineal, lo que indica que la regularización no tuvo un impacto considerable.\n",
        "- **Train MSE (32.09) vs. Test MSE (40.42):** Consistente con el RMSE.\n",
        "- **Train MAE (32.09) vs. Test MAE (40.42):** Los errores absolutos medios son altos en ambos conjuntos.\n",
        "- **Train MAPE (0.19) vs. Test MAPE (0.23):** El error porcentual absoluto medio es similar al de la regresión lineal.\n",
        "\n",
        "**Conclusión:** El modelo Lasso no mejora significativamente respecto a la regresión lineal, indicando que la regularización no es efectiva en este caso.\n",
        "\n",
        "## Ridge:\n",
        "- **Train RMSE (32.51) vs. Test RMSE (40.46):** El error en ambos conjuntos es alto y no muestra una mejora significativa en comparación con la regresión lineal.\n",
        "- **Train R² (0.63) vs. Test R² (0.58):** La capacidad predictiva es similar a la de la regresión lineal y Lasso.\n",
        "- **Train MSE (32.51) vs. Test MSE (40.46):** Consistente con el RMSE.\n",
        "- **Train MAE (32.51) vs. Test MAE (40.46):** Los errores absolutos medios son altos.\n",
        "- **Train MAPE (0.19) vs. Test MAPE (0.23):** El error porcentual absoluto medio sigue la tendencia de los otros modelos.\n",
        "\n",
        "**Conclusión:** Ridge no mejora el rendimiento en comparación con los otros modelos, lo que sugiere que la regularización L2 no es beneficiosa en este contexto.\n",
        "\n",
        "## ElasticNet:\n",
        "- **Train RMSE (32.57) vs. Test RMSE (40.45):** El error es prácticamente idéntico al de Lasso y Ridge.\n",
        "- **Train R² (0.63) vs. Test R² (0.58):** Capacidad predictiva similar a los demás modelos regularizados.\n",
        "- **Train MSE (32.57) vs. Test MSE (40.45):** Consistente con el RMSE.\n",
        "- **Train MAE (32.57) vs. Test MAE (40.45):** Errores absolutos medios altos en ambos conjuntos.\n",
        "- **Train MAPE (0.19) vs. Test MAPE (0.23):** El error porcentual es el mismo que en los otros modelos de regularización.\n",
        "\n",
        "**Conclusión:** ElasticNet no mejora el rendimiento respecto a Lasso o Ridge, lo que sugiere que la combinación de penalizaciones L1 y L2 no aporta beneficios en este caso.\n",
        "\n",
        "---\n",
        "\n",
        "# Conclusión parcial:\n",
        "- **Modelos de Regularización (Lasso, Ridge, ElasticNet) y Regresión Lineal:**\n",
        "  - Presentan errores similares en los conjuntos de datos.\n",
        "  - La regularización no mejora significativamente el rendimiento, lo que sugiere que estos modelos no capturan adecuadamente la complejidad de los datos.\n",
        "\n",
        "- **Modelos Basados en Gradiente:**\n",
        "  - **SGD y Mini-Batch Gradient Descent** ofrecen un rendimiento superior, con mejores métricas de error y capacidad predictiva.\n",
        "  - **Batch Gradient Descent** parece estar subajustado, con mejor rendimiento en el conjunto de prueba que en el de entrenamiento.\n",
        "\n",
        "- **General:**\n",
        "  - Los métodos de gradiente, en particular **Mini-Batch Gradient Descent**, logran un buen equilibrio entre ajuste y generalización, mientras que los modelos de regularización no muestran mejoras claras.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimización de los hiperparámetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "regresiones_lineales = {\n",
        "    \"Lasso\": LassoCV(alphas=np.logspace(-6, 2, 50), cv=5, max_iter=10000),\n",
        "    \"Ridge\": RidgeCV(alphas=np.logspace(-6, 2, 50), cv=5),\n",
        "    \"ElasticNet\": ElasticNetCV(alphas=np.logspace(-4, 4, 20), l1_ratio=np.linspace(0.1, 1, 10), cv=5, random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados_finales = []\n",
        "\n",
        "# Regresión lineal simple\n",
        "resultados_finales.append(evaluar_modelo(regresion_lineal, \"Regresión Lineal\", X_train_scaled, y_train, X_test_scaled, y_test))\n",
        "\n",
        "# Gradiente descendente (modelos obtenidos por SGD, Batch y Mini-batch)\n",
        "W_sgd = stochastic_gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.001, epochs=15)\n",
        "W_batch = gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.01, epochs=650)\n",
        "W_mini_batch = mini_batch_gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.01, epochs=1120, batch_size=240)\n",
        "\n",
        "# Evaluar los modelos obtenidos por gradientes\n",
        "resultados_finales.append(evaluar_gradiente(W_sgd, X_train_scaled, X_test_scaled, y_train, y_test, \"SGD\"))\n",
        "resultados_finales.append(evaluar_gradiente(W_batch, X_train_scaled, X_test_scaled, y_train, y_test, \"Batch Gradient Descent\"))\n",
        "resultados_finales.append(evaluar_gradiente(W_mini_batch, X_train_scaled, X_test_scaled, y_train, y_test, \"Mini-Batch Gradient Descent\"))\n",
        "# Evaluación de regularización (Lasso, Ridge, ElasticNet)\n",
        "for name, regressor in regresiones_lineales.items():\n",
        "    regressor.fit(X_train_scaled, y_train)\n",
        "    resultados_finales.append(evaluar_modelo(regressor, name, X_train_scaled, y_train, X_test_scaled, y_test))\n",
        "\n",
        "# Mostrar los resultados finales\n",
        "resultados_df = pd.DataFrame(resultados_finales)\n",
        "resultados_df.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparación de Códigos y Resultados Obtenidos\n",
        "\n",
        "## Cambios en el código\n",
        "\n",
        "### 1. Parámetros de Lasso y Ridge:\n",
        "\n",
        "- **Lasso:**\n",
        "  - En el primer código, el rango de `alpha` es más reducido `(np.logspace(-4, 4, 20))`, mientras que en el segundo código, se expandió para cubrir un rango más amplio `(np.logspace(-6, 2, 50))`, lo cual permite encontrar una mejor regularización en escenarios donde un ajuste fino es necesario.\n",
        "  - Además, en el segundo código, se aumentó `max_iter` a `10,000` en Lasso, lo que permite más iteraciones y mayor tiempo para que el algoritmo converja en casos difíciles.\n",
        "\n",
        "- **Ridge:**\n",
        "  - En el primer código, el rango de `alpha` también es más estrecho `(np.logspace(-4, 4, 20))`, mientras que en el segundo se incrementa a un rango más amplio de `np.logspace(-6, 2, 50)`. Esto da mayor flexibilidad en la búsqueda del valor óptimo de regularización.\n",
        "\n",
        "### 2. Parámetros de los Gradientes:\n",
        "\n",
        "- **SGD:**\n",
        "  - En la primera configuración: `epochs=1000` y `lr=0.001`.\n",
        "  - En la segunda configuración: `epochs=15` y `lr=0.001`. La reducción significativa en el número de épocas muestra mejoras importantes en los resultados, sugiriendo que un menor número de iteraciones permitió evitar el sobreajuste.\n",
        "\n",
        "- **Batch Gradient Descent:**\n",
        "  - Primera configuración: `epochs=1000` y `lr=0.001`.\n",
        "  - Segunda configuración: `epochs=650` y `lr=0.01`. Aumentar la tasa de aprendizaje junto con la reducción en las épocas mostró mejoras significativas tanto en el conjunto de entrenamiento como en el de prueba.\n",
        "\n",
        "- **Mini-Batch Gradient Descent:**\n",
        "  - Primera configuración: `epochs=100`, `lr=0.01`, y `batch_size=25`.\n",
        "  - Segunda configuración: `epochs=1120`, `lr=0.01`, y `batch_size=240`. Aunque el número de épocas y el tamaño del batch cambiaron considerablemente, los resultados no muestran variaciones significativas entre ambas configuraciones.\n",
        "\n",
        "## Comparación de Resultados\n",
        "\n",
        "| Modelo                        | Train RMSE (Antes) | Train RMSE (Después) | Test RMSE (Antes) | Test RMSE (Después) | Train R2 (Antes) | Train R2 (Después) | Test R2 (Antes) | Test R2 (Después) |\n",
        "|-------------------------------|--------------------|----------------------|-------------------|---------------------|------------------|--------------------|-----------------|-------------------|\n",
        "| **SGD**                        | 5.6756             | 5.7697               | 6.2220            | 6.0887              | 0.6350           | 0.6229             | 0.5954          | 0.6125            |\n",
        "| **Batch Gradient Descent**      | 8.3126             | 5.7342               | 7.7006            | 6.2868              | 0.2171           | 0.6275             | 0.3802          | 0.5869            |\n",
        "| **Mini-Batch Gradient Descent** | 5.7310             | 5.6642               | 6.5099            | 6.3808              | 0.6279           | 0.6365             | 0.5751          | 0.5745            |\n",
        "| **Lasso**                      | 32.0895            | 32.1041              | 40.4151           | 40.4127             | 0.6364           | 0.6363             | 0.5776          | 0.5776            |\n",
        "| **Ridge**                      | 32.5057            | 32.4612              | 40.4589           | 40.4688             | 0.6317           | 0.6322             | 0.5772          | 0.5771            |\n",
        "\n",
        "## Evaluación de los Resultados:\n",
        "\n",
        "- **SGD:**\n",
        "  La reducción de épocas mejoró los resultados en el conjunto de prueba. El Test RMSE bajó de 6.22 a 6.09, y el Test R2 subió de 0.595 a 0.612. Esto sugiere que la modificación de hiperparámetros fue efectiva para evitar el sobreajuste en este modelo.\n",
        "\n",
        "- **Batch Gradient Descent:**\n",
        "  Se observa una mejora importante en los resultados de entrenamiento y prueba. El Train RMSE mejoró considerablemente de 8.31 a 5.73, y el Test RMSE bajó de 7.70 a 6.29. El ajuste en los hiperparámetros claramente favoreció un mejor rendimiento del modelo.\n",
        "\n",
        "- **Mini-Batch Gradient Descent:**\n",
        "  Los cambios en los hiperparámetros no causaron una mejora significativa en el rendimiento. El Test RMSE y el Test R2 se mantuvieron bastante similares entre ambas configuraciones.\n",
        "\n",
        "- **Lasso y Ridge:**\n",
        "  Los modelos regularizados apenas mostraron diferencias en sus métricas, lo que indica que los cambios en los hiperparámetros no afectaron de manera sustancial el rendimiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparación de Modelos\n",
        "\n",
        "Para determinar cuál es el mejor modelo de regresión, usaremos como métrica principal el **RMSE** (Root Mean Squared Error) en el conjunto de **prueba**, ya que mide la magnitud de los errores en la predicción y nos permite identificar qué tan bien el modelo generaliza en datos no vistos. También consideraremos el **R²**, que nos indica qué proporción de la variabilidad de la variable dependiente es explicada por el modelo.\n",
        "\n",
        "#### Resumen de las métricas clave:\n",
        "- **Regresión Lineal**:\n",
        "  - Test RMSE: 40.45\n",
        "  - Test R²: 0.58\n",
        "- **SGD**:\n",
        "  - Test RMSE: 6.09\n",
        "  - Test R²: 0.61\n",
        "- **Batch Gradient Descent**:\n",
        "  - Test RMSE: 6.29\n",
        "  - Test R²: 0.59\n",
        "- **Mini-Batch Gradient Descent**:\n",
        "  - Test RMSE: 6.38\n",
        "  - Test R²: 0.57\n",
        "- **Lasso**:\n",
        "  - Test RMSE: 40.41\n",
        "  - Test R²: 0.58\n",
        "- **Ridge**:\n",
        "  - Test RMSE: 40.47\n",
        "  - Test R²: 0.58\n",
        "- **ElasticNet**:\n",
        "  - Test RMSE: 40.45\n",
        "  - Test R²: 0.58\n",
        "\n",
        "#### Análisis:\n",
        "1. **SGD** tiene el mejor **RMSE** en el conjunto de prueba con un valor de **6.09**, lo que significa que tiene el menor error de predicción entre todos los modelos. Su **R²** de **0.61** indica que explica el 61% de la variabilidad en el conjunto de prueba, lo cual es el mayor valor entre los modelos probados.\n",
        "\n",
        "2. **Batch Gradient Descent** muestra un **RMSE** cercano de **6.29**, con un **R²** de **0.59**, lo que significa que también tiene un buen rendimiento en la predicción, aunque ligeramente inferior al de SGD.\n",
        "\n",
        "3. **Mini-Batch Gradient Descent** tiene un **RMSE** de **6.38** y un **R²** de **0.57**, lo que lo sitúa muy cerca de los otros métodos de gradiente descendente, con un error algo mayor pero aún competitivo.\n",
        "\n",
        "4. Los modelos tradicionales de regresión regularizada como **Lasso**, **Ridge**, **ElasticNet**, y la **Regresión Lineal** tienen RMSEs significativamente más altos, todos alrededor de **40.45**, lo que sugiere que estos modelos no generalizan tan bien como los métodos de gradiente en este conjunto de datos. Sin embargo, su **R²** es razonable (0.58), lo que indica que explican una parte importante de la variabilidad de los datos, pero sus errores absolutos son mucho mayores.\n",
        "\n",
        "#### Conclusión:\n",
        "El modelo **SGD (Stochastic Gradient Descent)** es el mejor en este caso, con el menor **Test RMSE** (6.09) y el mayor **R²** (0.61), lo que lo hace el más adecuado para este conjunto de datos. Sin embargo, los modelos **Batch Gradient Descent** y **Mini-Batch Gradient Descent** también ofrecen un buen rendimiento, aunque con ligeros aumentos en el error de predicción. Los modelos tradicionales como la Regresión Lineal, Lasso, Ridge, y ElasticNet no parecen ser los más óptimos, dado su mayor RMSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Conclusión final del trabajo\n",
        "\n",
        "Este proyecto de análisis de precios de casas se centró en la preparación de datos, imputación de valores faltantes y comparación de múltiples enfoques de regresión para predecir el valor de una vivienda (variable objetivo \"MEDV\").\n",
        "\n",
        "1. **Preprocesamiento de datos**: \n",
        "   - La eliminación de filas con un alto número de valores faltantes,esto se hizo para garantizar la calidad de los datos. Se implementó un método de imputación KNN para manejar valores faltantes, lo que ayudó a preservar las observaciones al completar las características faltantes con datos similares.\n",
        "\n",
        "2. **Análisis exploratorio**:\n",
        "   - Los análisis gráficos como los boxplots y pairplots permitieron identificar la distribución de las variables y observar posibles correlaciones entre ellas. Este tipo de visualización fue útil para detectar posibles relaciones entre las variables explicativas y la variable objetivo, lo cual guió la elección de los modelos.\n",
        "\n",
        "3. **Modelado y evaluación**:\n",
        "   - Se implementaron múltiples técnicas de regresión lineal regularizada, como Ridge, Lasso y ElasticNet, junto con modelos de gradiente descendente (GD, SGD, y Mini-Batch GD). Estos modelos se ajustaron usando datos escalados para mejorar la convergencia y la estabilidad de los coeficientes del modelo.\n",
        "   - Los resultados se evaluaron utilizando métricas como el MSE (Error Cuadrático Medio), MAE (Error Absoluto Medio), y MAPE (Porcentaje de Error Absoluto Medio), lo que permitió comparar el rendimiento entre los distintos enfoques.\n",
        "   - Se implementaron gráficos para visualizar los errores de entrenamiento y prueba a lo largo de las iteraciones, lo que permitió un monitoreo visual de la optimización del modelo.\n",
        "\n",
        "### Reflexiones finales:\n",
        "Vimos cómo distintas técnicas de modelado pueden abordar problemas de regresión con eficacia, especialmente cuando se aplican correctamente los pasos de preprocesamiento y selección de modelos. La integración de modelos de regularización junto con técnicas de gradiente descendente proporcionó una visión completa de los enfoques lineales para predicción.\n",
        "En conclusión, pusimos realizar un análisis robusto y mejorar la precisión en la predicción de precios de casas."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
