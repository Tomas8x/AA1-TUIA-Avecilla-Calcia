{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trabajo Práctico N° 1\n",
        "\n",
        "**Año:** 2024  \n",
        "\n",
        "**Materia:** Aprendizaje Automatico 1\n",
        "\n",
        "**Integrantes:** Avecilla Tomás, Calcia Franco\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emdFaxAN6_xs"
      },
      "source": [
        "### Diccionario  de Datos\n",
        "\n",
        "| Columna       | Descripción                                                                                          |\n",
        "|---------------|---------------------------------------------------------------------------------------------------------------|\n",
        "| **CRIM** | Tasa de criminalidad per cápita por ciudad.                       |\n",
        "| **ZN**   | Proporción de terrenos residenciales zonificados para lotes de más de 25,000 pies cuadrados.                         |\n",
        "| **INDUS**   | Proporción de acres de negocios no minoristas por ciudad.                         |\n",
        "| **CHAS** | Variable dummy del río Charles (1 si el tramo limita con el río; 0 de lo contrario).                                                             |\n",
        "| **NOX**   | Concentración de óxidos de nitrógeno (partes por 10 millones) [parts/10M].                                                          |\n",
        "| **RM**        | Número promedio de habitaciones por vivienda.|\n",
        "| **AGE**    | Proporción de unidades ocupadas por sus propietarios construidas antes de 1940.                                                        |\n",
        "| **DIS**   | Distancias ponderadas a cinco centros de empleo de Boston.       |\n",
        "| **RAD** | índice de accesibilidad a las autopistas radiales.                                                             |\n",
        "| **TAX**   | Tasa de impuesto sobre la propiedad a valor completo por $10,000 [$/10k].                                                          |\n",
        "| **PTRATIO**        | Proporción alumno-maestro por ciudad.|\n",
        "| **B**    | El resultado de la ecuación B=1000(Bk - 0.63)^2 donde Bk es la proporción de negros por ciudad.                                                        |\n",
        "| **LSTAT**   | % de población de menor estatus socioeconómico.       |\n",
        "| **MEDV** *(Variable de salida)*  | Valor mediano de las viviendas ocupadas por sus propietarios en miles de dólares [k$].   | \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVVs2jH58Qyt"
      },
      "source": [
        "# Preparacion del entorno de Trabajo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik47qb-VCF8L"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv (Python 3.10.11)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/Usuario/Desktop/TUIA/AA1-TUIA-Avecilla-Calcia/AA1-TUIA-Avecilla-Calcia/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, mean_absolute_error\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from sklearn.preprocessing import RobustScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VLVElyf2CPwO"
      },
      "outputs": [],
      "source": [
        "df_precios_casas = pd.read_csv(\"house-prices-tp.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThPT2Wc76_xx"
      },
      "source": [
        "# Train-Test\n",
        "Decidimos hacer la division del dataset antes de comenzar el analisis y hacer cualquier tratado de datos ya que necesitamos que el dataset de testeo sea tomado como datos desconocidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Dcn_d2I66_xx"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_precios_casas.drop(columns=['MEDV']), df_precios_casas['MEDV'], test_size=0.2, random_state=42)\n",
        "\n",
        "df_entrenamiento = pd.concat([X_train,y_train],axis=1)\n",
        "df_test = pd.concat([X_test,y_test],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SKvtI-c6_xu"
      },
      "source": [
        "# Análisis Exploratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g8o5BJABC6N"
      },
      "source": [
        "## Limpieza de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfJumZYU6_xv"
      },
      "source": [
        "### Verificamos valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "hJbcu1P8CepE",
        "outputId": "210603ac-50ec-4bde-c05b-27805c6efebc"
      },
      "outputs": [],
      "source": [
        "conteo_nan = df_entrenamiento.isnull().sum()\n",
        "conteo_nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD4F-YKtBS0_"
      },
      "source": [
        "Como primera medida eliminaremos las fila que tengan la variable de salida nula o mas de 11 columnas nulas ya que las consideramos irrelevantes para el analisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n08LNR7CSWf7",
        "outputId": "e1f63442-36f9-4234-be25-0a69c9cd5b15"
      },
      "outputs": [],
      "source": [
        "filas_nan = []\n",
        "\n",
        "for index, row in df_entrenamiento.iterrows():\n",
        "    # Verificamos si la fila tiene más de 11 NaN o si el valor de MEDV es NaN\n",
        "    if row.isnull().sum() > 11 or pd.isnull(row['MEDV']):\n",
        "        filas_nan.append(index)\n",
        "\n",
        "df_entrenamiento.drop(index=filas_nan, inplace=True)\n",
        "\n",
        "print(f\"Filas eliminadas: {len(filas_nan)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "XbwelUT-6_xw",
        "outputId": "e21e8a57-0362-4220-a33d-841b5507d152"
      },
      "outputs": [],
      "source": [
        "conteo_nan = df_entrenamiento.isnull().sum()\n",
        "conteo_nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amymG2Eb6_xw"
      },
      "source": [
        "Imputaremos la columna binaria con la moda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ww_xBD7L6_xw"
      },
      "outputs": [],
      "source": [
        "df_entrenamiento['CHAS'] = df_entrenamiento['CHAS'].fillna(df_entrenamiento['CHAS'].mode()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZOTyJj9Dcgr"
      },
      "source": [
        "Y el resto de columnas seran imputadas con KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "GKff5cv5FjJ1"
      },
      "outputs": [],
      "source": [
        "imputer = KNNImputer(n_neighbors=5)\n",
        "df_entrenamiento = pd.DataFrame(imputer.fit_transform(df_entrenamiento), columns=df_entrenamiento.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conteo_nan = df_entrenamiento.isnull().sum()\n",
        "conteo_nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E_PD9c56_xy"
      },
      "source": [
        "### Exploracion de outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7uhm6C46_xy",
        "outputId": "2f723d8e-70e0-4d21-e979-562b6210a3e2"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "num_columns = len(df_entrenamiento.columns)\n",
        "\n",
        "max_plots_per_figure = 12\n",
        "num_figures = (num_columns + max_plots_per_figure - 1) // max_plots_per_figure\n",
        "\n",
        "for fig_index in range(num_figures):\n",
        "    start_index = fig_index * max_plots_per_figure\n",
        "    end_index = min(start_index + max_plots_per_figure, num_columns)\n",
        "\n",
        "    plt.figure(figsize=(15, 5 * ((end_index - start_index + 2) // 2)))\n",
        "\n",
        "    for i, column in enumerate(df_entrenamiento.columns[start_index:end_index]):\n",
        "        plt.subplot((end_index - start_index + 2) // 3, 3, i + 1)\n",
        "        if column == 'CHAS':\n",
        "            sns.countplot(data=df_entrenamiento, x='CHAS')\n",
        "            plt.title('Distribución de CHAS')\n",
        "        else:\n",
        "            sns.boxplot(data=df_entrenamiento[column], color=\"skyblue\")\n",
        "            plt.title(column)\n",
        "        plt.xlabel('')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96eGHe2ECaDW"
      },
      "source": [
        "Podemos notar varias variables con presencia de outliers por lo cual deberiamos hacer un analisis mas profundo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLXpoCtiC_3a",
        "outputId": "38c90ffb-ab42-4407-e598-7394eef7ddc3"
      },
      "outputs": [],
      "source": [
        "resultados_atipicos = {}\n",
        "\n",
        "for columna in df_entrenamiento.columns:\n",
        "    if df_entrenamiento[columna].dtype in ['int64', 'float64']:\n",
        "        Q1 = df_entrenamiento[columna].quantile(0.25)\n",
        "        Q3 = df_entrenamiento[columna].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        limite_inferior = Q1 - 1.5 * IQR\n",
        "        limite_superior = Q3 + 1.5 * IQR\n",
        "\n",
        "        es_atipico = (df_entrenamiento[columna] < limite_inferior) | (df_entrenamiento[columna] > limite_superior)\n",
        "\n",
        "        cantidad_atipicos = es_atipico.sum()\n",
        "        porcentaje_atipicos = (cantidad_atipicos / len(df_entrenamiento)) * 100\n",
        "\n",
        "        resultados_atipicos[columna] = porcentaje_atipicos\n",
        "\n",
        "for columna, porcentaje in resultados_atipicos.items():\n",
        "    print(f\"Columna: {columna} - Porcentaje de valores atípicos: {porcentaje:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPEfoYlPARvl"
      },
      "source": [
        "## Analisis Descriptivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmTVC1F2CYUP",
        "outputId": "7ecd76c3-410b-4827-922f-2020fd4b1000"
      },
      "outputs": [],
      "source": [
        "df_entrenamiento.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrzmnuYo6_xv",
        "outputId": "5b008ddb-94a9-45cf-e763-c0ce7bc439d2"
      },
      "outputs": [],
      "source": [
        "df_entrenamiento.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFV4K2aV6_xx",
        "outputId": "8bde2f2b-25de-453d-b408-ef33b5f985c5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_entrenamiento['MEDV'], bins=30, kde=True)\n",
        "plt.title('variable Target')\n",
        "plt.xlabel('Precio')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um5Ol_236_xx",
        "outputId": "9925b20c-8856-4d1c-aeb8-b68c0c87036f"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "sns.pairplot(\n",
        "    df_entrenamiento,\n",
        "    diag_kind='kde',\n",
        "    plot_kws={'alpha': 0.6, 'color': 'orange', 's': 15},\n",
        "    diag_kws={'color': 'red', 'fill': True},  # Cambiado 'shade' por 'fill'\n",
        "    height=2.5,\n",
        "    aspect=1,\n",
        "    corner=True,\n",
        ")\n",
        "\n",
        "plt.suptitle('Pairplot de Variables del DataFrame de Entrenamiento', fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkaWvxkM6_xx"
      },
      "source": [
        "#### Matriz de correlación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1f0sfL66_xx",
        "outputId": "bd7a0dff-4cb6-43dc-d5f4-df1966045e4d"
      },
      "outputs": [],
      "source": [
        "corr_matrix = df_entrenamiento.corr()\n",
        "\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "\n",
        "colors = [(1, 1, 1), (1, 0, 0)]\n",
        "n_bins = 100\n",
        "cmap_name = 'red_white'\n",
        "cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='vlag', center=0, vmin=-1, vmax=1, linewidths=0.5)\n",
        "plt.title('Matriz de correlación')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpc15AMDD7d7"
      },
      "source": [
        "Notamos una fuerte relacion entre las variables TAX-RAD (0.88) y NOX-INDUS (0.74)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdsAROI-EpSO"
      },
      "source": [
        "# Valores nulos en dataset de testeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "o1zC6MbAE1jv",
        "outputId": "c2fb35d1-4cb2-495a-e1d3-94afa4ac29f6"
      },
      "outputs": [],
      "source": [
        "df_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMfeXjptFDCA"
      },
      "source": [
        "Usamos el mismo criterio que en el dataset de entrenamiento para eliminar filas completas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxbG6zjfFCcw",
        "outputId": "a6377bb8-e26c-40ff-b168-d9e4556bb119"
      },
      "outputs": [],
      "source": [
        "filas_nan = []\n",
        "\n",
        "for index, row in df_test.iterrows():\n",
        "    # Verificamos si la fila tiene más de 11 NaN o si el valor de MEDV es NaN\n",
        "    if row.isnull().sum() > 11 or pd.isnull(row['MEDV']):\n",
        "        filas_nan.append(index)\n",
        "\n",
        "df_test.drop(index=filas_nan, inplace=True)\n",
        "\n",
        "print(f\"Filas eliminadas: {len(filas_nan)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTpS3cJeFXjR"
      },
      "source": [
        "Aqui repetimos el criterio de rellenar con la moda que en el caso del entrenamiento fue de `0`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "9yD5FH3TFRz5"
      },
      "outputs": [],
      "source": [
        "df_test['CHAS'] = df_test['CHAS'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "DOXkJmUYF14D",
        "outputId": "6daf488a-ef02-44eb-bd8b-1cb1730efd19"
      },
      "outputs": [],
      "source": [
        "df_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyhwFsycFrhr"
      },
      "source": [
        "Y por ultimo usamos el mismo `imputer` para rellenar los restantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "1GX2JLISFi2C"
      },
      "outputs": [],
      "source": [
        "df_test = pd.DataFrame(imputer.fit_transform(df_test), columns=df_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "KX6mCAn1F2az",
        "outputId": "d6ed770d-0aca-4f57-8477-d2d44533309b"
      },
      "outputs": [],
      "source": [
        "df_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Escalar los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separar en X_train, y_train, X_test, y_test\n",
        "X_train = df_entrenamiento.drop(columns=['MEDV'])\n",
        "y_train = df_entrenamiento['MEDV']\n",
        "X_test = df_test.drop(columns=['MEDV'])\n",
        "y_test = df_test['MEDV']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escalar los datos\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Regresión lineal simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regresion_lineal = LinearRegression()\n",
        "regresion_lineal.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gradientes Descendentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradiente Descendente (Batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gradient_descent(X_train, y_train, X_val, y_val, lr, epochs):\n",
        "    \"\"\"\n",
        "    shapes:\n",
        "        X_train = nxm\n",
        "        y_train = nx1\n",
        "        X_val = pxm\n",
        "        y_val = px1\n",
        "        W = mx1\n",
        "    \"\"\"\n",
        "    n = X_train.shape[0]  # Número de ejemplos de entrenamiento\n",
        "    m = X_train.shape[1]  # Número de características\n",
        "\n",
        "    o = X_val.shape[0]  # Número de ejemplos de validación\n",
        "\n",
        "    # Poner columna de unos a las matrices X para el término de sesgo (bias)\n",
        "    X_train = np.hstack((np.ones((n, 1)), X_train))\n",
        "    X_val = np.hstack((np.ones((o, 1)), X_val))\n",
        "\n",
        "    # Convertir y_train y y_val a arrays de NumPy y asegurarse de que sean vectores columna\n",
        "    y_train = y_train.to_numpy().reshape(-1, 1)\n",
        "    y_val = y_val.to_numpy().reshape(-1, 1)\n",
        "\n",
        "    # Inicializar pesos aleatorios\n",
        "    W = np.random.randn(m + 1).reshape(m + 1, 1)\n",
        "\n",
        "    train_errors = []  # Para almacenar el error de entrenamiento en cada época\n",
        "    val_errors = []    # Para almacenar el error de validación en cada época\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        # Calcular predicción y error de entrenamiento\n",
        "        prediction_train = np.matmul(X_train, W)\n",
        "        error_train = y_train - prediction_train\n",
        "        train_mse = np.mean(error_train ** 2)\n",
        "        train_errors.append(train_mse)\n",
        "\n",
        "        # Calcular predicción y error de validación\n",
        "        prediction_val = np.matmul(X_val, W)\n",
        "        error_val = y_val - prediction_val\n",
        "        val_mse = np.mean(error_val ** 2)\n",
        "        val_errors.append(val_mse)\n",
        "\n",
        "        # Calcular el gradiente y actualizar pesos\n",
        "        grad_sum = np.sum(error_train * X_train, axis=0)\n",
        "        grad_mul = -2 / n * grad_sum  # 1xm\n",
        "        gradient = np.transpose(grad_mul).reshape(-1, 1)  # mx1\n",
        "\n",
        "        W = W - (lr * gradient)\n",
        "\n",
        "    # Graficar errores de entrenamiento y validación\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_errors, label='Error de entrenamiento')\n",
        "    plt.plot(val_errors, label='Error de validación')\n",
        "    plt.xlabel('Época')\n",
        "    plt.ylabel('Error cuadrático medio')\n",
        "    plt.legend()\n",
        "    plt.title('Error de entrenamiento y validación vs iteraciones (GD)')\n",
        "    plt.show()\n",
        "\n",
        "    return W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradiente Descendente Estocastico (SGD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(X_train, y_train, X_test, y_test, lr, epochs):\n",
        "    n = X_train.shape[0]\n",
        "    m = X_train.shape[1]\n",
        "\n",
        "    # Agregar el término de sesgo (bias) a las matrices de entrada\n",
        "    X_train = np.hstack((np.ones((n, 1)), X_train))\n",
        "    X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "    # Inicializar los pesos de forma aleatoria\n",
        "    W = np.random.randn(m + 1, 1)\n",
        "\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "\n",
        "    # Convertir y_train y y_test a numpy.ndarray\n",
        "    y_train = y_train.to_numpy().reshape(-1, 1)\n",
        "    y_test = y_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        # Permutación aleatoria de los datos\n",
        "        permutation = np.random.permutation(n)\n",
        "        X_train = X_train[permutation]\n",
        "        y_train = y_train[permutation].reshape(-1, 1)  # Asegurarse de que y_train sea un vector columna\n",
        "\n",
        "        for j in range(n):\n",
        "            # Obtener una muestra aleatoria de un solo dato para hacer SGD\n",
        "            x_sample = X_train[j].reshape(1, -1)\n",
        "            y_sample = y_train[j]\n",
        "\n",
        "            prediction = np.matmul(x_sample, W)\n",
        "            error = y_sample - prediction\n",
        "            train_mse = error ** 2\n",
        "            train_errors.append(train_mse[0])\n",
        "\n",
        "            prediction_test = np.matmul(X_test, W)\n",
        "            error_test = y_test - prediction_test  # Asegurarse de que y_test sea un vector columna\n",
        "            test_mse = np.mean(error_test ** 2)\n",
        "            test_errors.append(test_mse)\n",
        "\n",
        "            gradient = -2 * error * x_sample.T\n",
        "            W = W - (lr * gradient)\n",
        "\n",
        "            \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_errors, label='Error de entrenamiento')\n",
        "    plt.plot(test_errors, label='Error de prueba')\n",
        "    plt.xlabel('Iteración')\n",
        "    plt.ylabel('Error cuadrático medio')\n",
        "    plt.legend()\n",
        "    plt.title('Error de entrenamiento y prueba vs iteraciones (SGD)')\n",
        "    plt.show()\n",
        "\n",
        "    return W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradiente Descedente por lotes (Mini-Batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mini_batch_gradient_descent(X_train, y_train, X_test, y_test, lr, epochs, batch_size):\n",
        "    n = X_train.shape[0]\n",
        "    m = X_train.shape[1]\n",
        "\n",
        "    X_train = np.hstack((np.ones((n, 1)), X_train))\n",
        "    X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "    y_train = y_train.to_numpy().reshape(-1, 1)\n",
        "    y_test = y_test.to_numpy().reshape(-1, 1)\n",
        "\n",
        "    W = np.random.randn(m + 1).reshape(-1, 1)\n",
        "\n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "\n",
        "    for i in range(epochs):\n",
        "        # Permutación aleatoria de los datos\n",
        "        permutation = np.random.permutation(n)\n",
        "        X_train = X_train[permutation]\n",
        "        y_train = y_train[permutation]\n",
        "\n",
        "        for j in range(0, n, batch_size):\n",
        "            # Obtener un lote (mini-batch) de datos\n",
        "            x_batch = X_train[j:j+batch_size, :]\n",
        "            y_batch = y_train[j:j+batch_size].reshape(-1, 1)\n",
        "\n",
        "            prediction = np.matmul(x_batch, W)\n",
        "            error = y_batch - prediction\n",
        "            train_mse = np.mean(error ** 2)\n",
        "            train_errors.append(train_mse)\n",
        "\n",
        "            gradient = -2 * np.matmul(x_batch.T, error) / batch_size\n",
        "\n",
        "            W = W - (lr * gradient)\n",
        "\n",
        "            prediction_test = np.matmul(X_test, W)\n",
        "            error_test = y_test - prediction_test\n",
        "            test_mse = np.mean(error_test ** 2)\n",
        "            test_errors.append(test_mse)\n",
        "\n",
        "            \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(train_errors, label='Error de entrenamiento')\n",
        "    plt.plot(test_errors, label='Error de prueba')\n",
        "    plt.xlabel('Iteración')\n",
        "    plt.ylabel('Error cuadrático medio')\n",
        "    plt.legend()\n",
        "    plt.title('Error de entrenamiento y prueba vs iteraciones (Mini-Batch GD)')\n",
        "    plt.show()\n",
        "\n",
        "    return W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelos de Regularización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "regresiones_lineales = {\n",
        "    \"Lasso\": LassoCV(alphas=np.logspace(-4, 4, 20), cv=5, random_state=42),\n",
        "    \"Ridge\": RidgeCV(alphas=np.logspace(-4, 4, 20), cv=5),\n",
        "    \"ElasticNet\": ElasticNetCV(alphas=np.logspace(-4, 4, 20), l1_ratio=np.linspace(0.1, 1, 10), cv=5, random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluación de Modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluar_modelo(modelo, nombre_modelo, X_train, y_train, X_test, y_test):\n",
        "    y_train_pred = modelo.predict(X_train)\n",
        "    y_test_pred = modelo.predict(X_test)\n",
        "\n",
        "    resultados = {\n",
        "        \"Modelo\": nombre_modelo,\n",
        "        \"Train RMSE\": np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "        \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
        "        \"Train R2\": r2_score(y_train, y_train_pred),\n",
        "        \"Test R2\": r2_score(y_test, y_test_pred),\n",
        "        \"Train MSE\": mean_squared_error(y_train, y_train_pred),\n",
        "        \"Test MSE\": mean_squared_error(y_test, y_test_pred),\n",
        "        \"Train MAE\": mean_absolute_error(y_train, y_train_pred),\n",
        "        \"Test MAE\": mean_absolute_error(y_test, y_test_pred),\n",
        "        \"Train MAPE\": mean_absolute_percentage_error(y_train, y_train_pred),\n",
        "        \"Test MAPE\": mean_absolute_percentage_error(y_test, y_test_pred)\n",
        "    }\n",
        "\n",
        "    return resultados\n",
        "\n",
        "def calcular_metricas(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
        "    return mse, mae, mape\n",
        "\n",
        "def evaluar_gradiente(W, X_train, X_test, y_train, y_test, nombre_modelo):\n",
        "    X_train_bias = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "    X_test_bias = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "    y_train_pred = np.dot(X_train_bias, W).flatten()\n",
        "    y_test_pred = np.dot(X_test_bias, W).flatten()\n",
        "\n",
        "    train_mse, train_mae, train_mape = calcular_metricas(y_train, y_train_pred)\n",
        "    test_mse, test_mae, test_mape = calcular_metricas(y_test, y_test_pred)\n",
        "\n",
        "    resultados = {\n",
        "        \"Modelo\": nombre_modelo,\n",
        "        \"Train RMSE\": np.sqrt(train_mse),\n",
        "        \"Test RMSE\": np.sqrt(test_mse),\n",
        "        \"Train R2\": r2_score(y_train, y_train_pred),\n",
        "        \"Test R2\": r2_score(y_test, y_test_pred),\n",
        "        \"Train MSE\": train_mse,\n",
        "        \"Test MSE\": test_mse,\n",
        "        \"Train MAE\": train_mae,\n",
        "        \"Test MAE\": test_mae,\n",
        "        \"Train MAPE\": train_mape,\n",
        "        \"Test MAPE\": test_mape\n",
        "    }\n",
        "\n",
        "    return resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados_finales = []\n",
        "\n",
        "# Regresión lineal simple\n",
        "resultados_finales.append(evaluar_modelo(regresion_lineal, \"Regresión Lineal\", X_train_scaled, y_train, X_test_scaled, y_test))\n",
        "\n",
        "# Gradiente descendente (modelos obtenidos por SGD, Batch y Mini-batch)\n",
        "W_sgd = stochastic_gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.001, epochs=1000)\n",
        "W_batch = gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.001, epochs=1000)\n",
        "W_mini_batch = mini_batch_gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.01, epochs=100, batch_size=25)\n",
        "\n",
        "# Evaluar los modelos obtenidos por gradientes\n",
        "resultados_finales.append(evaluar_gradiente(W_sgd, X_train_scaled, X_test_scaled, y_train, y_test, \"SGD\"))\n",
        "resultados_finales.append(evaluar_gradiente(W_batch, X_train_scaled, X_test_scaled, y_train, y_test, \"Batch Gradient Descent\"))\n",
        "resultados_finales.append(evaluar_gradiente(W_mini_batch, X_train_scaled, X_test_scaled, y_train, y_test, \"Mini-Batch Gradient Descent\"))\n",
        "# Evaluación de regularización (Lasso, Ridge, ElasticNet)\n",
        "for name, regressor in regresiones_lineales.items():\n",
        "    regressor.fit(X_train_scaled, y_train)\n",
        "    resultados_finales.append(evaluar_modelo(regressor, name, X_train_scaled, y_train, X_test_scaled, y_test))\n",
        "\n",
        "# Mostrar los resultados finales\n",
        "resultados_df = pd.DataFrame(resultados_finales)\n",
        "resultados_df.head(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpretación de los Gráficos\n",
        "\n",
        "## 1. Stochastic Gradient Descent (SGD)\n",
        "\n",
        "**Análisis:**\n",
        "- El error de entrenamiento es extremadamente errático, con oscilaciones muy grandes. Esto es esperado en SGD, ya que utiliza una muestra aleatoria de los datos en cada iteración, lo que genera una alta variabilidad.\n",
        "- El error de prueba, por otro lado, es mucho más estable y más bajo, lo que sugiere que, a pesar de las oscilaciones del entrenamiento, el modelo generaliza bien en el conjunto de prueba.\n",
        "\n",
        "**Conclusión:** Aunque SGD tiene un comportamiento muy volátil en el entrenamiento, parece estar generalizando bien en el conjunto de prueba. Sin embargo, esta volatilidad podría reducirse ajustando la tasa de aprendizaje o implementando técnicas como el decaimiento de la tasa de aprendizaje.\n",
        "\n",
        "## 2. Gradient Descent (GD)\n",
        "\n",
        "**Análisis:**\n",
        "- El error disminuye rápidamente al principio y luego se estabiliza alrededor de una misma línea para el entrenamiento y la validación, lo que indica que el modelo está convergiendo de manera efectiva.\n",
        "- No hay oscilaciones pronunciadas, lo cual es característico del Gradient Descent estándar, ya que utiliza todo el conjunto de datos para cada iteración.\n",
        "\n",
        "**Conclusión:** GD muestra un comportamiento de convergencia suave y estable, con un bajo riesgo de sobreajuste, ya que los errores de entrenamiento y validación son casi idénticos.\n",
        "\n",
        "## 3. Mini-Batch Gradient Descent (MBGD)\n",
        "\n",
        "**Análisis:**\n",
        "- El error de entrenamiento disminuye rápidamente en las primeras iteraciones, lo cual es un comportamiento esperado.\n",
        "- Se observa que oscila considerablemente a lo largo de las iteraciones, lo que es típico en el Mini-Batch GD debido a la naturaleza de los lotes pequeños de datos.\n",
        "- El error de prueba sigue un patrón similar pero tiene menos variabilidad, lo que sugiere que el modelo es estable en el conjunto de prueba a pesar de las oscilaciones en el entrenamiento.\n",
        "\n",
        "**Conclusión:** Mini-Batch GD logra una rápida convergencia inicial, pero las oscilaciones indican que podría necesitar una tasa de aprendizaje más pequeña o un tamaño de lote más grande para reducir la variabilidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpretación del Cuadro\n",
        "\n",
        "## Regresión Lineal:\n",
        "- **Train RMSE (5.66) vs. Test RMSE (6.36):** El error en el conjunto de prueba es ligeramente mayor que en el conjunto de entrenamiento, lo que puede indicar un buen ajuste, aunque podría haber margen de mejora en la generalización.\n",
        "- **Train R² (0.63) vs. Test R² (0.58):** El modelo explica el 63% de la variación en el conjunto de entrenamiento y el 58% en el conjunto de prueba, lo que muestra una ligera disminución en la capacidad predictiva cuando se prueban datos nuevos.\n",
        "- **Train MSE (32.07) vs. Test MSE (40.45):** El error cuadrático medio es considerablemente mayor en el conjunto de prueba, reflejando la misma tendencia que el RMSE.\n",
        "- **Train MAE (3.81) vs. Test MAE (4.22):** El error absoluto medio aumenta en el conjunto de prueba, lo que indica que el modelo es menos preciso con datos nuevos.\n",
        "- **Train MAPE (0.19) vs. Test MAPE (0.23):** El error porcentual absoluto medio también incrementa en el conjunto de prueba, sugiriendo una disminución en la precisión predictiva.\n",
        "\n",
        "**Conclusión:** El modelo de regresión lineal presenta un desempeño moderado, con un aumento en los errores al pasar al conjunto de prueba, lo que podría señalar sobreajuste.\n",
        "\n",
        "## SGD (Stochastic Gradient Descent):\n",
        "- **Train RMSE (5.68) vs. Test RMSE (6.46):** El error en el conjunto de prueba es un poco mayor que en el entrenamiento, lo que es normal y sugiere una buena generalización.\n",
        "- **Train R² (0.65) vs. Test R² (0.34):** La capacidad predictiva disminuye considerablemente en el conjunto de prueba, lo que indica que el modelo no se ajusta bien a datos no vistos.\n",
        "- **Train MSE (32.21) vs. Test MSE (41.78):** El error cuadrático medio sigue la misma tendencia que el RMSE, con un aumento en el conjunto de prueba.\n",
        "- **Train MAE (3.78) vs. Test MAE (4.21):** El error absoluto medio es bajo en ambos conjuntos.\n",
        "- **Train MAPE (0.18) vs. Test MAPE (0.23):** El error porcentual absoluto medio es consistente, aunque con una ligera pérdida de precisión en el conjunto de prueba.\n",
        "\n",
        "**Conclusión:** Aunque el modelo SGD generaliza bien, la gran diferencia en el R² entre los conjuntos de entrenamiento y prueba sugiere que podría necesitar ajustes adicionales para mejorar la precisión en datos nuevos.\n",
        "\n",
        "## Batch Gradient Descent:\n",
        "- **Train RMSE (7.79) vs. Test RMSE (7.59):** El error en el conjunto de prueba es ligeramente menor que en el entrenamiento, lo que puede indicar que el modelo está subajustado.\n",
        "- **Train R² (0.29) vs. Test R² (0.39):** El modelo tiene un mejor desempeño en el conjunto de prueba que en el entrenamiento, lo cual es indicativo de subajuste.\n",
        "- **Train MSE (63.23) vs. Test MSE (57.59):** El error cuadrático medio es mayor en el conjunto de entrenamiento, lo que sigue la misma tendencia que el RMSE.\n",
        "- **Train MAE (6.12) vs. Test MAE (6.18):** El error absoluto medio es muy similar en ambos conjuntos.\n",
        "- **Train MAPE (0.28) vs. Test MAPE (0.31):** El error porcentual absoluto medio es moderadamente mayor en el conjunto de prueba.\n",
        "\n",
        "**Conclusión:** El modelo Batch Gradient Descent parece estar subajustado, ya que su desempeño en el conjunto de prueba es mejor que en el conjunto de entrenamiento.\n",
        "\n",
        "## Mini-Batch Gradient Descent:\n",
        "- **Train RMSE (5.78) vs. Test RMSE (6.49):** El error aumenta en el conjunto de prueba, pero sigue siendo relativamente bajo, lo que indica que el modelo generaliza bien.\n",
        "- **Train R² (0.62) vs. Test R² (0.56):** La capacidad predictiva del modelo se mantiene fuerte, aunque disminuye ligeramente en el conjunto de prueba.\n",
        "- **Train MSE (33.15) vs. Test MSE (42.21):** El error cuadrático medio aumenta en el conjunto de prueba, siguiendo la tendencia del RMSE.\n",
        "- **Train MAE (4.11) vs. Test MAE (4.34):** El error absoluto medio es bajo en ambos conjuntos, aunque ligeramente mayor en el conjunto de prueba.\n",
        "- **Train MAPE (0.21) vs. Test MAPE (0.25):** El error porcentual absoluto medio es bajo, pero aumenta ligeramente en el conjunto de prueba.\n",
        "\n",
        "**Conclusión:** El modelo Mini-Batch Gradient Descent ofrece un buen balance entre ajuste y generalización, con errores relativamente bajos y consistentes.\n",
        "\n",
        "## Lasso:\n",
        "- **Train RMSE (5.66) vs. Test RMSE (6.63):** El error en el conjunto de prueba es mayor que en el entrenamiento, similar al comportamiento de la regresión lineal.\n",
        "- **Train R² (0.63) vs. Test R² (0.57):** La capacidad predictiva es similar a la regresión lineal, con una ligera disminución en el conjunto de prueba.\n",
        "- **Train MSE (32.08) vs. Test MSE (40.41):** El error cuadrático medio refleja la misma tendencia que el RMSE.\n",
        "- **Train MAE (3.80) vs. Test MAE (4.19):** El error absoluto medio es bajo, aunque aumenta en el conjunto de prueba.\n",
        "- **Train MAPE (0.19) vs. Test MAPE (0.23):** El error porcentual absoluto medio también aumenta en el conjunto de prueba.\n",
        "\n",
        "**Conclusión:** Lasso no ofrece mejoras significativas en comparación con la regresión lineal, indicando que la regularización L1 no es efectiva en este caso.\n",
        "\n",
        "## Ridge:\n",
        "- **Train RMSE (5.70) vs. Test RMSE (6.36):** El error es alto en ambos conjuntos y sigue una tendencia similar a los modelos lineales.\n",
        "- **Train R² (0.63) vs. Test R² (0.58):** La capacidad predictiva es similar a los modelos anteriores.\n",
        "- **Train MSE (32.50) vs. Test MSE (40.45):** Los errores cuadráticos medios son consistentes con el RMSE.\n",
        "- **Train MAE (3.80) vs. Test MAE (4.16):** Los errores absolutos medios son similares en ambos conjuntos.\n",
        "- **Train MAPE (0.19) vs. Test MAPE (0.23):** El error porcentual absoluto medio es consistente con los otros modelos.\n",
        "\n",
        "**Conclusión:** Ridge no mejora significativamente el rendimiento con respecto a los modelos previos, lo que sugiere que la regularización L2 no es efectiva en este contexto.\n",
        "\n",
        "## ElasticNet:\n",
        "- **Train RMSE (5.70) vs. Test RMSE (6.36):** Los errores son casi idénticos a los de los modelos de regularización Lasso y Ridge.\n",
        "- **Train R² (0.63) vs. Test R² (0.58):** Capacidad predictiva similar a los demás modelos.\n",
        "- **Train MSE (32.57) vs. Test MSE (40.45):** Los errores cuadráticos medios son consistentes con el RMSE.\n",
        "- **Train MAE (3.80) vs. Test MAE (4.16):** El error absoluto medio es alto en ambos conjuntos.\n",
        "- **Train MAPE (0.19) vs. Test MAPE (0.23):** El error porcentual absoluto medio es consistente con los otros modelos.\n",
        "\n",
        "**Conclusión:** ElasticNet no mejora significativamente respecto a Lasso o Ridge, lo que sugiere que la combinación de penalizaciones L1 y L2 no aporta beneficios en este caso.\n",
        "\n",
        "---\n",
        "\n",
        "# Conclusión parcial:\n",
        "- **Modelos de Regularización (Lasso, Ridge, ElasticNet) y Regresión Lineal:**\n",
        "  - Presentan errores similares.\n",
        "  - La regularización no mejora significativamente el rendimiento.\n",
        "\n",
        "- **Modelos Basados en Gradiente:**\n",
        "  - **Mini-Batch Gradient Descent** y **SGD** muestran un rendimiento superior.\n",
        "  - **Batch Gradient Descent** parece estar subajustado.\n",
        "\n",
        "- **General:**\n",
        "  - Los métodos de gradiente, especialmente **Mini-Batch Gradient Descent**, logran un buen equilibrio entre ajuste y generalización."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimización de los hiperparámetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "regresiones_lineales = {\n",
        "    \"Lasso\": LassoCV(alphas=np.logspace(-6, 2, 50), cv=5, max_iter=10000),\n",
        "    \"Ridge\": RidgeCV(alphas=np.logspace(-6, 2, 50), cv=5),\n",
        "    \"ElasticNet\": ElasticNetCV(alphas=np.logspace(-4, 4, 20), l1_ratio=np.linspace(0.1, 1, 10), cv=5, random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados_finales = []\n",
        "\n",
        "# Regresión lineal simple\n",
        "resultados_finales.append(evaluar_modelo(regresion_lineal, \"Regresión Lineal\", X_train_scaled, y_train, X_test_scaled, y_test))\n",
        "\n",
        "# Gradiente descendente (modelos obtenidos por SGD, Batch y Mini-batch)\n",
        "W_sgd = stochastic_gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.001, epochs=15)\n",
        "W_batch = gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.01, epochs=650)\n",
        "W_mini_batch = mini_batch_gradient_descent(X_train_scaled, y_train, X_test_scaled, y_test, lr=0.01, epochs=1120, batch_size=240)\n",
        "\n",
        "# Evaluar los modelos obtenidos por gradientes\n",
        "resultados_finales.append(evaluar_gradiente(W_sgd, X_train_scaled, X_test_scaled, y_train, y_test, \"SGD\"))\n",
        "resultados_finales.append(evaluar_gradiente(W_batch, X_train_scaled, X_test_scaled, y_train, y_test, \"Batch Gradient Descent\"))\n",
        "resultados_finales.append(evaluar_gradiente(W_mini_batch, X_train_scaled, X_test_scaled, y_train, y_test, \"Mini-Batch Gradient Descent\"))\n",
        "# Evaluación de regularización (Lasso, Ridge, ElasticNet)\n",
        "for name, regressor in regresiones_lineales.items():\n",
        "    regressor.fit(X_train_scaled, y_train)\n",
        "    resultados_finales.append(evaluar_modelo(regressor, name, X_train_scaled, y_train, X_test_scaled, y_test))\n",
        "\n",
        "# Mostrar los resultados finales\n",
        "resultados_df = pd.DataFrame(resultados_finales)\n",
        "resultados_df.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparación de Códigos y Resultados Obtenidos\n",
        "\n",
        "## Cambios en el código\n",
        "\n",
        "### 1. Parámetros de Lasso y Ridge:\n",
        "\n",
        "- **Lasso:**\n",
        "  - En el primer código, el rango de `alpha` es más reducido `(np.logspace(-4, 4, 20))`, mientras que en el segundo código, se expandió para cubrir un rango más amplio `(np.logspace(-6, 2, 50))`, lo cual permite encontrar una mejor regularización en escenarios donde un ajuste fino es necesario.\n",
        "  - Además, en el segundo código, se aumentó `max_iter` a `10,000` en Lasso, lo que permite más iteraciones y mayor tiempo para que el algoritmo converja en casos difíciles.\n",
        "\n",
        "- **Ridge:**\n",
        "  - En el primer código, el rango de `alpha` también es más estrecho `(np.logspace(-4, 4, 20))`, mientras que en el segundo se incrementa a un rango más amplio de `np.logspace(-6, 2, 50)`. Esto da mayor flexibilidad en la búsqueda del valor óptimo de regularización.\n",
        "\n",
        "### 2. Parámetros de los Gradientes:\n",
        "\n",
        "- **SGD:**\n",
        "  - En la primera configuración: `epochs=1000` y `lr=0.001`.\n",
        "  - En la segunda configuración: `epochs=15` y `lr=0.001`. La reducción significativa en el número de épocas muestra mejoras importantes en los resultados, sugiriendo que un menor número de iteraciones permitió evitar el sobreajuste.\n",
        "\n",
        "- **Batch Gradient Descent:**\n",
        "  - Primera configuración: `epochs=1000` y `lr=0.001`.\n",
        "  - Segunda configuración: `epochs=650` y `lr=0.01`. Aumentar la tasa de aprendizaje junto con la reducción en las épocas mostró mejoras significativas tanto en el conjunto de entrenamiento como en el de prueba.\n",
        "\n",
        "- **Mini-Batch Gradient Descent:**\n",
        "  - Primera configuración: `epochs=100`, `lr=0.01`, y `batch_size=25`.\n",
        "  - Segunda configuración: `epochs=1120`, `lr=0.01`, y `batch_size=240`. Aunque el número de épocas y el tamaño del batch cambiaron considerablemente, los resultados no muestran variaciones significativas entre ambas configuraciones.\n",
        "\n",
        "\n",
        "## Comparación de Resultados\n",
        "\n",
        "| Modelo                        | Train RMSE (Antes) | Train RMSE (Después) | Test RMSE (Antes) | Test RMSE (Después) | Train R2 (Antes) | Train R2 (Después) | Test R2 (Antes) | Test R2 (Después) |\n",
        "|-------------------------------|--------------------|----------------------|-------------------|---------------------|------------------|--------------------|-----------------|-------------------|\n",
        "| **SGD**                        | 5.681173           | 5.736999             | 6.460536           | 6.122241            | 0.634335          | 0.627114           | 0.563783         | 0.608271           |\n",
        "| **Batch Gradient Descent**      | 7.976447           | 5.713968             | 7.588523           | 6.335249            | 0.279182          | 0.630101           | 0.398162         | 0.580538           |\n",
        "| **Mini-Batch Gradient Descent** | 5.788892           | 5.666384             | 6.497669           | 6.411268            | 0.620337          | 0.636237           | 0.558754         | 0.570411           |\n",
        "| **Lasso**                      | 5.664760           | 5.666052             | 6.357286           | 6.357096            | 0.636445          | 0.636279           | 0.577615         | 0.577640           |\n",
        "| **Ridge**                      | 5.701377           | 5.697475             | 6.370033           | 6.361509            | 0.631730          | 0.632234           | 0.577156         | 0.577053           |\n",
        "\n",
        "## Evaluación de los Resultados:\n",
        "\n",
        "- **SGD:**\n",
        "  Se observa un pequeño aumento en el **Train RMSE** (de 5.68 a 5.74), pero el **Test RMSE** disminuyó de 6.46 a 6.12, lo que indica que el modelo mejoró su rendimiento en los datos de prueba después del ajuste de hiperparámetros. El **Test R2** también subió de 0.56 a 0.61, lo que indica que el modelo es capaz de explicar mejor la variabilidad de los datos de prueba tras el ajuste.\n",
        "\n",
        "- **Batch Gradient Descent:**\n",
        "  El **Train RMSE** mejoró considerablemente (de 7.98 a 5.71), lo que indica que el modelo se ajustó mucho mejor a los datos de entrenamiento. Además, el **Test RMSE** bajó de 7.59 a 6.33, lo que sugiere que los ajustes de hiperparámetros tuvieron un impacto positivo, mejorando su capacidad para generalizar en los datos de prueba. El **Test R2** también mejoró de 0.40 a 0.58.\n",
        "\n",
        "- **Mini-Batch Gradient Descent:**\n",
        "  Las métricas también mejoraron tras el ajuste, aunque de manera menos dramática en comparación con otros modelos. El **Test RMSE** bajó ligeramente de 6.50 a 6.41, y el **Test R2** subió de 0.56 a 0.57. Estos cambios indican una mejora leve en el rendimiento general del modelo.\n",
        "\n",
        "- **Lasso:**\n",
        "  Las métricas para el modelo **Lasso** no cambiaron significativamente después del ajuste de hiperparámetros. El **Test RMSE** se mantuvo prácticamente igual (6.357 frente a 6.357) y el **Test R2** también permaneció casi idéntico (0.5776). Esto sugiere que los ajustes en los hiperparámetros no tuvieron un efecto notable en el rendimiento del modelo.\n",
        "\n",
        "- **Ridge:**\n",
        "  El modelo **Ridge** mostró una leve mejoría. El **Train RMSE** disminuyó de 5.70 a 5.69, mientras que el **Test RMSE** se mantuvo prácticamente igual (6.37 vs. 6.36). El **Test R2** también se mantuvo casi sin cambios. Esto indica que los ajustes de hiperparámetros tuvieron un impacto mínimo en el rendimiento del modelo.\n",
        "\n",
        "\n",
        "## Evaluación Global:\n",
        "\n",
        "Los cambios en los hiperparámetros tuvieron un impacto positivo más significativo en los modelos **SGD** y **Batch Gradient Descent**, con mejoras tanto en **Test RMSE** como en **Test R2**. **Mini-Batch Gradient Descent** también mostró una ligera mejora. Por otro lado, los modelos regularizados como **Lasso** y **Ridge** apenas mostraron cambios, lo que sugiere que las modificaciones en los hiperparámetros no fueron tan efectivas en estos casos.\n",
        "\n",
        "### Conclusión:\n",
        "- **SGD** y **Batch Gradient Descent** fueron los que más se beneficiaron de los ajustes, con mejoras notables en su capacidad de generalización.\n",
        "- **Lasso** y **Ridge** no mostraron grandes variaciones tras el ajuste de hiperparámetros, por lo que es probable que estos modelos ya estuvieran bien ajustados o que no sean tan sensibles a los cambios realizados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparación de Modelos\n",
        "\n",
        "Para determinar cuál es el mejor modelo de regresión, usaremos como métrica principal el **RMSE** (Root Mean Squared Error) en el conjunto de **prueba**, ya que mide la magnitud de los errores en la predicción y nos permite identificar qué tan bien el modelo generaliza en datos no vistos. También consideraremos el **R²**, que nos indica qué proporción de la variabilidad de la variable dependiente es explicada por el modelo.\n",
        "\n",
        "#### Resumen de las métricas clave:\n",
        "- **Regresión Lineal**:\n",
        "  - Test RMSE: 6.36\n",
        "  - Test R²: 0.58\n",
        "- **SGD**:\n",
        "  - Test RMSE: 6.12\n",
        "  - Test R²: 0.61\n",
        "- **Batch Gradient Descent**:\n",
        "  - Test RMSE: 6.34\n",
        "  - Test R²: 0.58\n",
        "- **Mini-Batch Gradient Descent**:\n",
        "  - Test RMSE: 6.41\n",
        "  - Test R²: 0.57\n",
        "- **Lasso**:\n",
        "  - Test RMSE: 6.36\n",
        "  - Test R²: 0.58\n",
        "- **Ridge**:\n",
        "  - Test RMSE: 6.36\n",
        "  - Test R²: 0.58\n",
        "- **ElasticNet**:\n",
        "  - Test RMSE: 6.36\n",
        "  - Test R²: 0.58\n",
        "\n",
        "\n",
        "#### Análisis:\n",
        "\n",
        "1. **SGD** tiene el mejor **RMSE** en el conjunto de prueba con un valor de **6.12**, lo que indica que tiene el menor error de predicción entre todos los modelos evaluados. Además, su **R²** de **0.61** es el más alto, lo que significa que explica el 61% de la variabilidad en los datos de prueba, lo que sugiere un excelente ajuste y capacidad de generalización.\n",
        "\n",
        "2. **Batch Gradient Descent** tiene un **RMSE** cercano de **6.34** con un **R²** de **0.58**. Aunque su error es ligeramente mayor que el de SGD, sigue mostrando un rendimiento muy competitivo y una buena capacidad para generalizar.\n",
        "\n",
        "3. **Mini-Batch Gradient Descent** tiene un **RMSE** de **6.41** y un **R²** de **0.57**. Aunque su rendimiento es ligeramente inferior a los métodos anteriores, sigue siendo competitivo con un error relativamente bajo y una buena capacidad de ajuste.\n",
        "\n",
        "4. Los modelos más tradicionales como la **Regresión Lineal**, **Lasso**, **Ridge** y **ElasticNet** tienen todos un **RMSE** de **6.36** y un **R²** de **0.58**. Esto indica que estos modelos no generalizan tan bien como los métodos de gradiente. Si bien explican una parte importante de la variabilidad de los datos (con un **R²** de 0.58), el error absoluto que presentan es mayor en comparación con SGD y Batch Gradient Descent.\n",
        "\n",
        "#### Conclusión:\n",
        "\n",
        "El modelo **SGD (Stochastic Gradient Descent)** se destaca como el mejor modelo en este conjunto de datos, con el menor **Test RMSE** de **6.12** y el mayor **R²** de **0.61**. Esto lo convierte en la opción más adecuada, ya que presenta el mejor equilibrio entre precisión y capacidad de generalización. **Batch Gradient Descent** también tiene un buen rendimiento, con un RMSE de **6.34**, lo que lo hace una alternativa viable. Por otro lado, los modelos tradicionales, como la **Regresión Lineal**, **Lasso**, **Ridge**, y **ElasticNet**, presentan un rendimiento inferior, aunque sus **R²** son similares, indicando que tienen más dificultades para reducir los errores absolutos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Conclusión final del trabajo\n",
        "\n",
        "Este proyecto de análisis de precios de casas se centró en la preparación de datos, manejo de valores atípicos, imputación de valores faltantes y comparación de múltiples enfoques de regresión para predecir el valor de una vivienda (variable objetivo \"MEDV\").\n",
        "\n",
        "1. **Preprocesamiento de datos**: \n",
        "   - La eliminación de filas con un alto número de valores faltantes,esto se hizo para garantizar la calidad de los datos. Se implementó un método de imputación KNN para manejar valores faltantes, lo que ayudó a preservar las observaciones al completar las características faltantes con datos similares.\n",
        "\n",
        "2. **Análisis exploratorio**:\n",
        "   - Los análisis gráficos como los boxplots y pairplots permitieron identificar la distribución de las variables y observar posibles correlaciones entre ellas. Este tipo de visualización fue útil para detectar posibles relaciones entre las variables explicativas y la variable objetivo, lo cual guió la elección de los modelos.\n",
        "\n",
        "3. **Modelado y evaluación**:\n",
        "   - Se implementaron múltiples técnicas de regresión lineal regularizada, como Ridge, Lasso y ElasticNet, junto con modelos de gradiente descendente (GD, SGD, y Mini-Batch GD). Estos modelos se ajustaron usando datos escalados para mejorar la convergencia y la estabilidad de los coeficientes del modelo.\n",
        "   - Los resultados se evaluaron utilizando métricas como el MSE (Error Cuadrático Medio), MAE (Error Absoluto Medio), y MAPE (Porcentaje de Error Absoluto Medio), lo que permitió comparar el rendimiento entre los distintos enfoques.\n",
        "   - Se implementaron gráficos para visualizar los errores de entrenamiento y prueba a lo largo de las iteraciones, lo que permitió un monitoreo visual de la optimización del modelo.\n",
        "\n",
        "\n",
        "### Reflexiones finales:\n",
        "A lo largo de este análisis, pudimos ver cómo diferentes técnicas de modelado pueden abordar con éxito problemas de regresión, siempre y cuando se sigan bien los pasos previos como el preprocesamiento y la selección adecuada de modelos. La combinación de modelos como Lasso y Ridge, junto con técnicas de gradiente descendente, nos ofreció una perspectiva clara de los enfoques lineales para hacer predicciones.\n",
        "\n",
        "En resumen, al combinar métodos como la imputación de datos, la detección de valores atípicos y el uso de varios modelos de regresión, logramos un análisis más sólido que mejora la precisión en la predicción de precios de viviendas."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
